{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People who haven't pooped in 2019 yet, why are...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221854</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Would you watch a show where a billionaire CEO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197524</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How would you feel about a feature where if so...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186368</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "      <td>175339</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reddit, how would you feel about a law that ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160311</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>Pokemon Go Update [2016-08-08]</td>\n",
       "      <td># [A Note From The Developers](http://pokemong...</td>\n",
       "      <td>7189</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18573</th>\n",
       "      <td>It boggles my mind that there is no way to sig...</td>\n",
       "      <td>It seems to me like a really obvious and easy ...</td>\n",
       "      <td>7168</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18574</th>\n",
       "      <td>Is it really a coincidence that both Niantic a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7117</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18575</th>\n",
       "      <td>The three footstep glitch has turned the game ...</td>\n",
       "      <td>The servers are slowly getting better. Hopeful...</td>\n",
       "      <td>7108</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18576</th>\n",
       "      <td>I feel like transfering second and third stage...</td>\n",
       "      <td>Not anything outrageous. Say a basic pokemon g...</td>\n",
       "      <td>7097</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18577 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      People who haven't pooped in 2019 yet, why are...   \n",
       "1      Would you watch a show where a billionaire CEO...   \n",
       "2      How would you feel about a feature where if so...   \n",
       "3               Stan Lee has passed away at 95 years old   \n",
       "4      Reddit, how would you feel about a law that ba...   \n",
       "...                                                  ...   \n",
       "18572                     Pokemon Go Update [2016-08-08]   \n",
       "18573  It boggles my mind that there is no way to sig...   \n",
       "18574  Is it really a coincidence that both Niantic a...   \n",
       "18575  The three footstep glitch has turned the game ...   \n",
       "18576  I feel like transfering second and third stage...   \n",
       "\n",
       "                                                    text  up_votes  \\\n",
       "0                                                    NaN    221854   \n",
       "1                                                    NaN    197524   \n",
       "2                                                    NaN    186368   \n",
       "3      As many of you know today is day that many of ...    175339   \n",
       "4                                                    NaN    160311   \n",
       "...                                                  ...       ...   \n",
       "18572  # [A Note From The Developers](http://pokemong...      7189   \n",
       "18573  It seems to me like a really obvious and easy ...      7168   \n",
       "18574                                                NaN      7117   \n",
       "18575  The servers are slowly getting better. Hopeful...      7108   \n",
       "18576  Not anything outrageous. Say a basic pokemon g...      7097   \n",
       "\n",
       "         subreddit  \n",
       "0      r/AskReddit  \n",
       "1      r/AskReddit  \n",
       "2      r/AskReddit  \n",
       "3      r/AskReddit  \n",
       "4      r/AskReddit  \n",
       "...            ...  \n",
       "18572  r/pokemongo  \n",
       "18573  r/pokemongo  \n",
       "18574  r/pokemongo  \n",
       "18575  r/pokemongo  \n",
       "18576  r/pokemongo  \n",
       "\n",
       "[18577 rows x 4 columns]"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "filepath = 'reddit_posts.xlsx'\n",
    "subreddit_df = pd.read_excel(filepath)\n",
    "subreddit_df = subreddit_df.drop(['Unnamed: 0'], axis=1)\n",
    "subreddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18577, 4)"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_df = subreddit_df[['subreddit', 'title', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>People who haven't pooped in 2019 yet, why are...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Would you watch a show where a billionaire CEO...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>How would you feel about a feature where if so...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Reddit, how would you feel about a law that ba...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>Pokemon Go Update [2016-08-08]</td>\n",
       "      <td># [A Note From The Developers](http://pokemong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18573</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>It boggles my mind that there is no way to sig...</td>\n",
       "      <td>It seems to me like a really obvious and easy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18574</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>Is it really a coincidence that both Niantic a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18575</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>The three footstep glitch has turned the game ...</td>\n",
       "      <td>The servers are slowly getting better. Hopeful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18576</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>I feel like transfering second and third stage...</td>\n",
       "      <td>Not anything outrageous. Say a basic pokemon g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18577 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subreddit                                              Title  \\\n",
       "0      r/AskReddit  People who haven't pooped in 2019 yet, why are...   \n",
       "1      r/AskReddit  Would you watch a show where a billionaire CEO...   \n",
       "2      r/AskReddit  How would you feel about a feature where if so...   \n",
       "3      r/AskReddit           Stan Lee has passed away at 95 years old   \n",
       "4      r/AskReddit  Reddit, how would you feel about a law that ba...   \n",
       "...            ...                                                ...   \n",
       "18572  r/pokemongo                     Pokemon Go Update [2016-08-08]   \n",
       "18573  r/pokemongo  It boggles my mind that there is no way to sig...   \n",
       "18574  r/pokemongo  Is it really a coincidence that both Niantic a...   \n",
       "18575  r/pokemongo  The three footstep glitch has turned the game ...   \n",
       "18576  r/pokemongo  I feel like transfering second and third stage...   \n",
       "\n",
       "                                                    Post  \n",
       "0                                                    NaN  \n",
       "1                                                    NaN  \n",
       "2                                                    NaN  \n",
       "3      As many of you know today is day that many of ...  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "18572  # [A Note From The Developers](http://pokemong...  \n",
       "18573  It seems to me like a really obvious and easy ...  \n",
       "18574                                                NaN  \n",
       "18575  The servers are slowly getting better. Hopeful...  \n",
       "18576  Not anything outrageous. Say a basic pokemon g...  \n",
       "\n",
       "[18577 rows x 3 columns]"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df = subreddit_df.rename(columns={\"subreddit\": \"Subreddit\",\"title\": \"Title\", \"text\": \"Post\"})\n",
    "nan_value = float(\"NaN\")\n",
    "subreddit_df.replace(\" \", nan_value, inplace=True)\n",
    "subreddit_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18577, 3)"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subreddit       0\n",
       "Title           0\n",
       "Post         4405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14172, 3)"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Professor Stephen Hawking has passed away at t...</td>\n",
       "      <td>We have lost one of the greatest minds in hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Suicide Prevention Megathread</td>\n",
       "      <td>With the news today of the passing of the amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>I can t breathe  Black lives matter</td>\n",
       "      <td>As the gap of the political divide in our worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Breaking News  Orlando Nightclub mass shooting</td>\n",
       "      <td>Update 3 19PM EST    Updated links below    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Subreddit                                              Title  \\\n",
       "3   r/AskReddit           Stan Lee has passed away at 95 years old   \n",
       "21  r/AskReddit  Professor Stephen Hawking has passed away at t...   \n",
       "34  r/AskReddit                      Suicide Prevention Megathread   \n",
       "48  r/AskReddit               I can t breathe  Black lives matter    \n",
       "55  r/AskReddit    Breaking News  Orlando Nightclub mass shooting    \n",
       "\n",
       "                                                 Post  \n",
       "3   As many of you know today is day that many of ...  \n",
       "21  We have lost one of the greatest minds in hist...  \n",
       "34  With the news today of the passing of the amaz...  \n",
       "48  As the gap of the political divide in our worl...  \n",
       "55    Update 3 19PM EST    Updated links below    ...  "
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df['Post'] = subreddit_df['Post'].apply(lambda x: re.sub('[^a-z A-Z 0-9]',' ', x))\n",
    "subreddit_df['Title'] = subreddit_df['Title'].apply(lambda x: re.sub('[^a-zA-Z0-9]',' ', x))\n",
    "subreddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Professor Stephen Hawking has passed away at t...</td>\n",
       "      <td>We have lost one of the greatest minds in hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Suicide Prevention Megathread</td>\n",
       "      <td>With the news today of the passing of the amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>I can t breathe  Black lives matter</td>\n",
       "      <td>As the gap of the political divide in our worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Breaking News  Orlando Nightclub mass shooting</td>\n",
       "      <td>Update 3 19PM EST    Updated links below    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14167</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>3 Months After His Death  the Gym in our Town ...</td>\n",
       "      <td>UPDATE 2  The name of the Gym has been change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14168</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>Pokemon Go Update  2016 08 08</td>\n",
       "      <td>A Note From The Developers  http   pokemong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14169</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>It boggles my mind that there is no way to sig...</td>\n",
       "      <td>It seems to me like a really obvious and easy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14170</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>The three footstep glitch has turned the game ...</td>\n",
       "      <td>The servers are slowly getting better  Hopeful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14171</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>I feel like transfering second and third stage...</td>\n",
       "      <td>Not anything outrageous  Say a basic pokemon g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14172 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subreddit                                              Title  \\\n",
       "0      r/AskReddit           Stan Lee has passed away at 95 years old   \n",
       "1      r/AskReddit  Professor Stephen Hawking has passed away at t...   \n",
       "2      r/AskReddit                      Suicide Prevention Megathread   \n",
       "3      r/AskReddit               I can t breathe  Black lives matter    \n",
       "4      r/AskReddit    Breaking News  Orlando Nightclub mass shooting    \n",
       "...            ...                                                ...   \n",
       "14167  r/pokemongo  3 Months After His Death  the Gym in our Town ...   \n",
       "14168  r/pokemongo                     Pokemon Go Update  2016 08 08    \n",
       "14169  r/pokemongo  It boggles my mind that there is no way to sig...   \n",
       "14170  r/pokemongo  The three footstep glitch has turned the game ...   \n",
       "14171  r/pokemongo  I feel like transfering second and third stage...   \n",
       "\n",
       "                                                    Post  \n",
       "0      As many of you know today is day that many of ...  \n",
       "1      We have lost one of the greatest minds in hist...  \n",
       "2      With the news today of the passing of the amaz...  \n",
       "3      As the gap of the political divide in our worl...  \n",
       "4        Update 3 19PM EST    Updated links below    ...  \n",
       "...                                                  ...  \n",
       "14167   UPDATE 2  The name of the Gym has been change...  \n",
       "14168     A Note From The Developers  http   pokemong...  \n",
       "14169  It seems to me like a really obvious and easy ...  \n",
       "14170  The servers are slowly getting better  Hopeful...  \n",
       "14171  Not anything outrageous  Say a basic pokemon g...  \n",
       "\n",
       "[14172 rows x 3 columns]"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/AskReddit', 'r/gaming', 'r/aww', 'r/Music', 'r/science',\n",
       "       'r/worldnews', 'r/videos', 'r/movies', 'r/Showerthoughts',\n",
       "       'r/IAmA', 'r/EarthPorn', 'r/askscience', 'r/Jokes',\n",
       "       'r/explainlikeimfive', 'r/books', 'r/LifeProTips', 'r/blog',\n",
       "       'r/DIY', 'r/sports', 'r/nottheonion', 'r/space', 'r/gadgets',\n",
       "       'r/television', 'r/GetMotivated', 'r/photoshopbattles',\n",
       "       'r/listentothis', 'r/UpliftingNews', 'r/tifu',\n",
       "       'r/InternetIsBeautiful', 'r/history', 'r/philosophy',\n",
       "       'r/Futurology', 'r/OldSchoolCool', 'r/WritingPrompts', 'r/nosleep',\n",
       "       'r/personalfinance', 'r/creepy', 'r/TwoXChromosomes',\n",
       "       'r/technology', 'r/Fitness', 'r/wholesomememes', 'r/politics',\n",
       "       'r/interestingasfuck', 'r/WTF', 'r/bestof', 'r/travel',\n",
       "       'r/oddlysatisfying', 'r/leagueoflegends', 'r/me_irl',\n",
       "       'r/lifehacks', 'r/NatureIsFuckingLit', 'r/pcmasterrace',\n",
       "       'r/dankmemes', 'r/Whatcouldgowrong', 'r/Tinder',\n",
       "       'r/relationship_advice', 'r/Minecraft', 'r/PS4', 'r/nba',\n",
       "       'r/woahdude', 'r/FoodPorn', 'r/photography', 'r/Overwatch',\n",
       "       'r/Unexpected', 'r/dadjokes', 'r/relationships', 'r/boardgames',\n",
       "       'r/instant_regret', 'r/programming', 'r/PublicFreakout',\n",
       "       'r/pokemon', 'r/pokemongo'], dtype=object)"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df['Subreddit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r/nosleep                998\n",
       "r/Jokes                  995\n",
       "r/IAmA                   994\n",
       "r/tifu                   989\n",
       "r/Fitness                989\n",
       "r/personalfinance        974\n",
       "r/dadjokes               906\n",
       "r/relationship_advice    869\n",
       "r/relationships          839\n",
       "r/LifeProTips            547\n",
       "r/history                543\n",
       "r/boardgames             536\n",
       "r/askscience             506\n",
       "r/TwoXChromosomes        505\n",
       "r/leagueoflegends        443\n",
       "r/books                  346\n",
       "r/explainlikeimfive      340\n",
       "r/photography            301\n",
       "r/nba                    258\n",
       "r/Music                  191\n",
       "r/pokemongo              127\n",
       "r/Showerthoughts         120\n",
       "r/WritingPrompts         118\n",
       "r/blog                    76\n",
       "r/pokemon                 75\n",
       "r/listentothis            67\n",
       "r/PS4                     66\n",
       "r/politics                64\n",
       "r/movies                  62\n",
       "r/television              60\n",
       "r/Overwatch               58\n",
       "r/philosophy              31\n",
       "r/technology              26\n",
       "r/lifehacks               20\n",
       "r/space                   19\n",
       "r/GetMotivated            16\n",
       "r/AskReddit               11\n",
       "r/gaming                  10\n",
       "r/Futurology               8\n",
       "r/interestingasfuck        6\n",
       "r/science                  5\n",
       "r/DIY                      5\n",
       "r/pcmasterrace             5\n",
       "r/woahdude                 5\n",
       "r/Tinder                   4\n",
       "r/InternetIsBeautiful      3\n",
       "r/Whatcouldgowrong         2\n",
       "r/photoshopbattles         2\n",
       "r/sports                   2\n",
       "r/me_irl                   2\n",
       "r/Minecraft                2\n",
       "r/programming              2\n",
       "r/videos                   2\n",
       "r/travel                   2\n",
       "r/oddlysatisfying          2\n",
       "r/dankmemes                2\n",
       "r/worldnews                1\n",
       "r/wholesomememes           1\n",
       "r/PublicFreakout           1\n",
       "r/gadgets                  1\n",
       "r/UpliftingNews            1\n",
       "r/Unexpected               1\n",
       "r/nottheonion              1\n",
       "r/instant_regret           1\n",
       "r/bestof                   1\n",
       "r/EarthPorn                1\n",
       "r/creepy                   1\n",
       "r/WTF                      1\n",
       "r/aww                      1\n",
       "r/OldSchoolCool            1\n",
       "r/NatureIsFuckingLit       1\n",
       "r/FoodPorn                 1\n",
       "Name: Subreddit, dtype: int64"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 10000)\n",
    "\n",
    "# value counts of subreddits \n",
    "subreddit_df['Subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_df.drop(subreddit_df[(subreddit_df['Subreddit'] == 'r/dadjokes') | \n",
    "                               (subreddit_df['Subreddit'] == 'r/tifu') | \n",
    "                               (subreddit_df['Subreddit'] == 'r/Jokes')].index, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df[subreddit_df['Subreddit'] == 'r/dadjokes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9025, 3), (2257, 3))"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(subreddit_df, test_size=0.20, random_state=42)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9025,), (9025,), (2257,), (2257,))"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arrange data into X features matrix and y target vector \n",
    "\n",
    "target = 'Subreddit'\n",
    "feature = 'Title'\n",
    "feature1 = 'Post'\n",
    "X_train = train[feature] + train[feature1] \n",
    "y_train = train[target]\n",
    "X_test = test[feature] + test[feature1] \n",
    "y_test = test[target]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('lsi',\n",
      "                 Pipeline(memory=None,\n",
      "                          steps=[('vect',\n",
      "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                                  decode_error='strict',\n",
      "                                                  dtype=<class 'numpy.float64'>,\n",
      "                                                  encoding='utf-8',\n",
      "                                                  input='content',\n",
      "                                                  lowercase=True, max_df=1.0,\n",
      "                                                  max_features=None, min_df=1,\n",
      "                                                  ngram_range=(1, 2), norm='l2',\n",
      "                                                  preprocessor=None,\n",
      "                                                  smooth_idf=True,\n",
      "                                                  stop_words='english',\n",
      "                                                  strip_accents=...\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=None, max_features='auto',\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=-1,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from random import randint\n",
    "from scipy.stats import randint\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "svd = TruncatedSVD(n_components=100, # svd = singular value decomposition \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators =100, n_jobs=-1, random_state=42)\n",
    "\n",
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "# Pipe\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])\n",
    "print(pipe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "\n",
    "parameters = {\n",
    "    'lsi__svd__n_components': scipy.stats.randint(5, 100),\n",
    "    'lsi__vect__max_features': scipy.stats.randint(100, 1000), # has to be an integer\n",
    "    'clf__n_estimators': scipy.stats.randint(10, 100),\n",
    "    'clf__max_depth': scipy.stats.randint(10, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khisl\\anaconda3\\envs\\post-here\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('lsi',\n",
       "                                              Pipeline(memory=None,\n",
       "                                                       steps=[('vect',\n",
       "                                                               TfidfVectorizer(analyzer='word',\n",
       "                                                                               binary=False,\n",
       "                                                                               decode_error='strict',\n",
       "                                                                               dtype=<class 'numpy.float64'>,\n",
       "                                                                               encoding='utf-8',\n",
       "                                                                               input='content',\n",
       "                                                                               lowercase=True,\n",
       "                                                                               max_df=1.0,\n",
       "                                                                               max_features=None,\n",
       "                                                                               min_df=1,\n",
       "                                                                               ngram_range=(1,\n",
       "                                                                                            2),\n",
       "                                                                               norm='l2',\n",
       "                                                                               preprocessor=None,\n",
       "                                                                               s...\n",
       "                                        'clf__n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B5B2A18F60>,\n",
       "                                        'lsi__svd__n_components': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B54AD0C048>,\n",
       "                                        'lsi__vect__max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B546A8FA90>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search = RandomizedSearchCV(pipe, parameters, n_iter=10, cv=5, n_jobs=-1, verbose=1)\n",
    "rand_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6024376731301938"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/AskReddit', 'r/DIY', 'r/EarthPorn', 'r/Fitness', 'r/FoodPorn',\n",
       "       'r/Futurology', 'r/GetMotivated', 'r/IAmA',\n",
       "       'r/InternetIsBeautiful', 'r/LifeProTips', 'r/Minecraft', 'r/Music',\n",
       "       'r/NatureIsFuckingLit', 'r/OldSchoolCool', 'r/Overwatch', 'r/PS4',\n",
       "       'r/PublicFreakout', 'r/Showerthoughts', 'r/Tinder',\n",
       "       'r/TwoXChromosomes', 'r/Unexpected', 'r/UpliftingNews', 'r/WTF',\n",
       "       'r/Whatcouldgowrong', 'r/WritingPrompts', 'r/askscience', 'r/aww',\n",
       "       'r/bestof', 'r/blog', 'r/boardgames', 'r/books', 'r/creepy',\n",
       "       'r/dankmemes', 'r/explainlikeimfive', 'r/gadgets', 'r/gaming',\n",
       "       'r/history', 'r/instant_regret', 'r/interestingasfuck',\n",
       "       'r/leagueoflegends', 'r/lifehacks', 'r/listentothis', 'r/me_irl',\n",
       "       'r/movies', 'r/nba', 'r/nosleep', 'r/nottheonion',\n",
       "       'r/oddlysatisfying', 'r/pcmasterrace', 'r/personalfinance',\n",
       "       'r/philosophy', 'r/photography', 'r/photoshopbattles', 'r/pokemon',\n",
       "       'r/pokemongo', 'r/politics', 'r/programming',\n",
       "       'r/relationship_advice', 'r/relationships', 'r/science', 'r/space',\n",
       "       'r/sports', 'r/technology', 'r/television', 'r/travel', 'r/videos',\n",
       "       'r/woahdude'], dtype=object)"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rand_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "          r/AskReddit       0.00      0.00      0.00         4\n",
      "            r/Fitness       0.77      0.90      0.83       188\n",
      "       r/GetMotivated       0.00      0.00      0.00         3\n",
      "               r/IAmA       0.69      0.91      0.79       206\n",
      "r/InternetIsBeautiful       0.00      0.00      0.00         1\n",
      "        r/LifeProTips       0.30      0.34      0.32       115\n",
      "          r/Minecraft       0.00      0.00      0.00         1\n",
      "              r/Music       0.52      0.32      0.39        38\n",
      "          r/Overwatch       0.00      0.00      0.00        13\n",
      "                r/PS4       0.00      0.00      0.00        12\n",
      "     r/Showerthoughts       0.22      0.07      0.11        27\n",
      "    r/TwoXChromosomes       0.51      0.41      0.45       105\n",
      "     r/WritingPrompts       0.14      0.04      0.06        28\n",
      "         r/askscience       0.32      0.47      0.38       108\n",
      "               r/blog       0.56      0.56      0.56         9\n",
      "         r/boardgames       0.60      0.86      0.70       111\n",
      "              r/books       0.81      0.83      0.82        70\n",
      "  r/explainlikeimfive       0.22      0.14      0.18        69\n",
      "             r/gaming       0.00      0.00      0.00         2\n",
      "            r/history       0.66      0.60      0.63       115\n",
      "  r/interestingasfuck       0.67      1.00      0.80         2\n",
      "    r/leagueoflegends       0.47      0.42      0.44        83\n",
      "          r/lifehacks       0.00      0.00      0.00         3\n",
      "       r/listentothis       0.20      0.11      0.14         9\n",
      "             r/movies       0.00      0.00      0.00         8\n",
      "                r/nba       0.68      0.23      0.35        56\n",
      "            r/nosleep       0.90      0.96      0.93       204\n",
      "    r/personalfinance       0.69      0.81      0.75       195\n",
      "         r/philosophy       0.00      0.00      0.00         6\n",
      "        r/photography       0.64      0.48      0.55        56\n",
      "            r/pokemon       0.57      0.25      0.35        16\n",
      "          r/pokemongo       0.69      0.31      0.43        29\n",
      "           r/politics       0.81      0.81      0.81        16\n",
      "        r/programming       0.00      0.00      0.00         1\n",
      "r/relationship_advice       0.52      0.53      0.53       167\n",
      "      r/relationships       0.61      0.64      0.62       154\n",
      "            r/science       0.00      0.00      0.00         3\n",
      "              r/space       0.00      0.00      0.00         3\n",
      "             r/sports       0.00      0.00      0.00         1\n",
      "         r/technology       0.00      0.00      0.00         2\n",
      "         r/television       0.00      0.00      0.00        14\n",
      "     r/wholesomememes       0.00      0.00      0.00         1\n",
      "           r/woahdude       0.00      0.00      0.00         2\n",
      "          r/worldnews       0.00      0.00      0.00         1\n",
      "\n",
      "             accuracy                           0.61      2257\n",
      "            macro avg       0.31      0.30      0.29      2257\n",
      "         weighted avg       0.58      0.61      0.59      2257\n",
      "\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0 170   0 ...   0   0   0]\n",
      " [  0   1   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   1 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khisl\\anaconda3\\envs\\post-here\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.classification_report(y_test, pred))\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "reddit_post =[ \"\"\"Hi, I lost my dog about 3 months ago and straight away started doing research \n",
    "            on rabbits to distract myself. I started asking my parents to get me a rabbit and \n",
    "            my mum found a rabbit and we went to pick him up. I still miss my dog so much and \n",
    "            I’m crying almost every night. I started looking into rehoming him but I don’t want \n",
    "            to get rid of him because I know I’ll regret it. He is so much work and even though \n",
    "            I knew how much work they were I still wanted one. \"\"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/TwoXChromosomes'], dtype=object)"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rand_search.predict(reddit_post)\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "post2 = [\"\"\"The plan to turn half the world into a reserve for nature. \n",
    "        Scientists and conservationists are proposing that up to half of \n",
    "        Earth’s land and oceans be protected for nature.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/askscience'], dtype=object)"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rand_search.predict(post2)\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "post3 = [\"\"\"Pets get flooded constantly and need help.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/LifeProTips'], dtype=object)"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rand_search.predict(post3)\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_subreddit(title, text, num_pred):\n",
    "    title = pd.Series(title)\n",
    "    text = pd.Series(text)\n",
    "    df = pd.concat([title, text])\n",
    "    proba = pd.Series(rand_search.predict_proba(df)[0])\n",
    "    proba = subreddit_df['Subreddit'].unique()\n",
    "    prediction = (pd.Series(proba).sort_values(ascending=False)).reset_index(drop=True)\n",
    "    if num_pred > 1:\n",
    "        return prediction[:num_pred] \n",
    "    else:\n",
    "        return prediction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    r/worldnews\n",
       "dtype: object"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_subreddit(['Any remote employees working US hours?'], [\"\"\"I see a lot of posts of \n",
    "                   people with remote US based jobs moving to Korea because they can work \n",
    "                   wherever they want regardless of time zone.\"\"\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         r/worldnews\n",
       "1          r/woahdude\n",
       "2    r/wholesomememes\n",
       "3            r/videos\n",
       "dtype: object"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_subreddit([\"\"\"Advice needed. My hair has become so much more oily within the past year. \n",
    "                   Can’t figure out why and it’s driving me crazy!\"\"\"], [\"\"\"I have always had somewhat oily hair.\n",
    "                   My second day hair had a little bit of oil to it, but nothing too drastic.\n",
    "                   I got highlights (my first experience with hair color) approximately a year ago. \n",
    "                   Since then, my hair has become grossly oily. It even feels oily when I blow dry \n",
    "                   it after a shower, when it should be completely clean.\"\"\"], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pickle import dump\n",
    "filename = 'post_here_model.pkl'\n",
    "pickle.dump(rand_search, open(filename, 'wb'))\n",
    "\n",
    "# to load model\n",
    "load_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "\n",
    "def compressed_pickle(title, data):\n",
    "    with bz2.BZ2File(title + '.pbz2', 'w') as f: \n",
    "        cPickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_pickle('post_here_model', rand_search) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load any compressed pickle file\n",
    "def decompress_pickle(file):\n",
    " data = bz2.BZ2File(file, 'rb')\n",
    " data = cPickle.load(data)\n",
    " return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = decompress_pickle('post_here_model.pbz2') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
