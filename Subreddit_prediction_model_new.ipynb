{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# # Create some tensors\n",
    "# a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "# b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "# c = tf.matmul(a, b)\n",
    "\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People who haven't pooped in 2019 yet, why are...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221854</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Would you watch a show where a billionaire CEO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197524</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How would you feel about a feature where if so...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186368</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "      <td>175339</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reddit, how would you feel about a law that ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160311</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>Pokemon Go Update [2016-08-08]</td>\n",
       "      <td># [A Note From The Developers](http://pokemong...</td>\n",
       "      <td>7189</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18573</th>\n",
       "      <td>It boggles my mind that there is no way to sig...</td>\n",
       "      <td>It seems to me like a really obvious and easy ...</td>\n",
       "      <td>7168</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18574</th>\n",
       "      <td>Is it really a coincidence that both Niantic a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7117</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18575</th>\n",
       "      <td>The three footstep glitch has turned the game ...</td>\n",
       "      <td>The servers are slowly getting better. Hopeful...</td>\n",
       "      <td>7108</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18576</th>\n",
       "      <td>I feel like transfering second and third stage...</td>\n",
       "      <td>Not anything outrageous. Say a basic pokemon g...</td>\n",
       "      <td>7097</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18577 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      People who haven't pooped in 2019 yet, why are...   \n",
       "1      Would you watch a show where a billionaire CEO...   \n",
       "2      How would you feel about a feature where if so...   \n",
       "3               Stan Lee has passed away at 95 years old   \n",
       "4      Reddit, how would you feel about a law that ba...   \n",
       "...                                                  ...   \n",
       "18572                     Pokemon Go Update [2016-08-08]   \n",
       "18573  It boggles my mind that there is no way to sig...   \n",
       "18574  Is it really a coincidence that both Niantic a...   \n",
       "18575  The three footstep glitch has turned the game ...   \n",
       "18576  I feel like transfering second and third stage...   \n",
       "\n",
       "                                                    text  up_votes  \\\n",
       "0                                                    NaN    221854   \n",
       "1                                                    NaN    197524   \n",
       "2                                                    NaN    186368   \n",
       "3      As many of you know today is day that many of ...    175339   \n",
       "4                                                    NaN    160311   \n",
       "...                                                  ...       ...   \n",
       "18572  # [A Note From The Developers](http://pokemong...      7189   \n",
       "18573  It seems to me like a really obvious and easy ...      7168   \n",
       "18574                                                NaN      7117   \n",
       "18575  The servers are slowly getting better. Hopeful...      7108   \n",
       "18576  Not anything outrageous. Say a basic pokemon g...      7097   \n",
       "\n",
       "         subreddit  \n",
       "0      r/AskReddit  \n",
       "1      r/AskReddit  \n",
       "2      r/AskReddit  \n",
       "3      r/AskReddit  \n",
       "4      r/AskReddit  \n",
       "...            ...  \n",
       "18572  r/pokemongo  \n",
       "18573  r/pokemongo  \n",
       "18574  r/pokemongo  \n",
       "18575  r/pokemongo  \n",
       "18576  r/pokemongo  \n",
       "\n",
       "[18577 rows x 4 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "filepath = 'reddit_posts.xlsx'\n",
    "subreddit_df = pd.read_excel(filepath)\n",
    "subreddit_df = subreddit_df.drop(['Unnamed: 0'], axis=1)\n",
    "subreddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18577, 4)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_df = subreddit_df[['subreddit', 'title', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>People who haven't pooped in 2019 yet, why are...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Would you watch a show where a billionaire CEO...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>How would you feel about a feature where if so...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Reddit, how would you feel about a law that ba...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>Pokemon Go Update [2016-08-08]</td>\n",
       "      <td># [A Note From The Developers](http://pokemong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18573</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>It boggles my mind that there is no way to sig...</td>\n",
       "      <td>It seems to me like a really obvious and easy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18574</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>Is it really a coincidence that both Niantic a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18575</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>The three footstep glitch has turned the game ...</td>\n",
       "      <td>The servers are slowly getting better. Hopeful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18576</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>I feel like transfering second and third stage...</td>\n",
       "      <td>Not anything outrageous. Say a basic pokemon g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18577 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subreddit                                              Title  \\\n",
       "0      r/AskReddit  People who haven't pooped in 2019 yet, why are...   \n",
       "1      r/AskReddit  Would you watch a show where a billionaire CEO...   \n",
       "2      r/AskReddit  How would you feel about a feature where if so...   \n",
       "3      r/AskReddit           Stan Lee has passed away at 95 years old   \n",
       "4      r/AskReddit  Reddit, how would you feel about a law that ba...   \n",
       "...            ...                                                ...   \n",
       "18572  r/pokemongo                     Pokemon Go Update [2016-08-08]   \n",
       "18573  r/pokemongo  It boggles my mind that there is no way to sig...   \n",
       "18574  r/pokemongo  Is it really a coincidence that both Niantic a...   \n",
       "18575  r/pokemongo  The three footstep glitch has turned the game ...   \n",
       "18576  r/pokemongo  I feel like transfering second and third stage...   \n",
       "\n",
       "                                                    Post  \n",
       "0                                                    NaN  \n",
       "1                                                    NaN  \n",
       "2                                                    NaN  \n",
       "3      As many of you know today is day that many of ...  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "18572  # [A Note From The Developers](http://pokemong...  \n",
       "18573  It seems to me like a really obvious and easy ...  \n",
       "18574                                                NaN  \n",
       "18575  The servers are slowly getting better. Hopeful...  \n",
       "18576  Not anything outrageous. Say a basic pokemon g...  \n",
       "\n",
       "[18577 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df = subreddit_df.rename(columns={\"subreddit\": \"Subreddit\",\"title\": \"Title\", \"text\": \"Post\"})\n",
    "nan_value = float(\"NaN\")\n",
    "subreddit_df.replace(\" \", nan_value, inplace=True)\n",
    "subreddit_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18577, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subreddit       0\n",
       "Title           0\n",
       "Post         4405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14172, 3)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Professor Stephen Hawking has passed away at t...</td>\n",
       "      <td>We have lost one of the greatest minds in hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Suicide Prevention Megathread</td>\n",
       "      <td>With the news today of the passing of the amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>I can’t breathe. Black lives matter.</td>\n",
       "      <td>As the gap of the political divide in our worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>[Breaking News] Orlando Nightclub mass-shooting.</td>\n",
       "      <td>**Update 3:19PM EST:** Updated links below\\n\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Subreddit                                              Title  \\\n",
       "3   r/AskReddit           Stan Lee has passed away at 95 years old   \n",
       "21  r/AskReddit  Professor Stephen Hawking has passed away at t...   \n",
       "34  r/AskReddit                      Suicide Prevention Megathread   \n",
       "48  r/AskReddit               I can’t breathe. Black lives matter.   \n",
       "55  r/AskReddit   [Breaking News] Orlando Nightclub mass-shooting.   \n",
       "\n",
       "                                                 Post  \n",
       "3   As many of you know today is day that many of ...  \n",
       "21  We have lost one of the greatest minds in hist...  \n",
       "34  With the news today of the passing of the amaz...  \n",
       "48  As the gap of the political divide in our worl...  \n",
       "55  **Update 3:19PM EST:** Updated links below\\n\\n...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subreddit_df['Post'] = subreddit_df['Post'].apply(lambda x: re.sub('[^a-z A-Z 0-9]',' ', x))\n",
    "# subreddit_df['Title'] = subreddit_df['Title'].apply(lambda x: re.sub('[^a-zA-Z0-9]',' ', x))\n",
    "subreddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Professor Stephen Hawking has passed away at t...</td>\n",
       "      <td>We have lost one of the greatest minds in hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Suicide Prevention Megathread</td>\n",
       "      <td>With the news today of the passing of the amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>I can’t breathe. Black lives matter.</td>\n",
       "      <td>As the gap of the political divide in our worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>[Breaking News] Orlando Nightclub mass-shooting.</td>\n",
       "      <td>**Update 3:19PM EST:** Updated links below\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14167</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>3 Months After His Death, the Gym in our Town ...</td>\n",
       "      <td>*UPDATE 2: The name of the Gym has been change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14168</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>Pokemon Go Update [2016-08-08]</td>\n",
       "      <td># [A Note From The Developers](http://pokemong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14169</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>It boggles my mind that there is no way to sig...</td>\n",
       "      <td>It seems to me like a really obvious and easy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14170</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>The three footstep glitch has turned the game ...</td>\n",
       "      <td>The servers are slowly getting better. Hopeful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14171</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>I feel like transfering second and third stage...</td>\n",
       "      <td>Not anything outrageous. Say a basic pokemon g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14172 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subreddit                                              Title  \\\n",
       "0      r/AskReddit           Stan Lee has passed away at 95 years old   \n",
       "1      r/AskReddit  Professor Stephen Hawking has passed away at t...   \n",
       "2      r/AskReddit                      Suicide Prevention Megathread   \n",
       "3      r/AskReddit               I can’t breathe. Black lives matter.   \n",
       "4      r/AskReddit   [Breaking News] Orlando Nightclub mass-shooting.   \n",
       "...            ...                                                ...   \n",
       "14167  r/pokemongo  3 Months After His Death, the Gym in our Town ...   \n",
       "14168  r/pokemongo                     Pokemon Go Update [2016-08-08]   \n",
       "14169  r/pokemongo  It boggles my mind that there is no way to sig...   \n",
       "14170  r/pokemongo  The three footstep glitch has turned the game ...   \n",
       "14171  r/pokemongo  I feel like transfering second and third stage...   \n",
       "\n",
       "                                                    Post  \n",
       "0      As many of you know today is day that many of ...  \n",
       "1      We have lost one of the greatest minds in hist...  \n",
       "2      With the news today of the passing of the amaz...  \n",
       "3      As the gap of the political divide in our worl...  \n",
       "4      **Update 3:19PM EST:** Updated links below\\n\\n...  \n",
       "...                                                  ...  \n",
       "14167  *UPDATE 2: The name of the Gym has been change...  \n",
       "14168  # [A Note From The Developers](http://pokemong...  \n",
       "14169  It seems to me like a really obvious and easy ...  \n",
       "14170  The servers are slowly getting better. Hopeful...  \n",
       "14171  Not anything outrageous. Say a basic pokemon g...  \n",
       "\n",
       "[14172 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/AskReddit', 'r/gaming', 'r/aww', 'r/Music', 'r/science',\n",
       "       'r/worldnews', 'r/videos', 'r/movies', 'r/Showerthoughts',\n",
       "       'r/IAmA', 'r/EarthPorn', 'r/askscience', 'r/Jokes',\n",
       "       'r/explainlikeimfive', 'r/books', 'r/LifeProTips', 'r/blog',\n",
       "       'r/DIY', 'r/sports', 'r/nottheonion', 'r/space', 'r/gadgets',\n",
       "       'r/television', 'r/GetMotivated', 'r/photoshopbattles',\n",
       "       'r/listentothis', 'r/UpliftingNews', 'r/tifu',\n",
       "       'r/InternetIsBeautiful', 'r/history', 'r/philosophy',\n",
       "       'r/Futurology', 'r/OldSchoolCool', 'r/WritingPrompts', 'r/nosleep',\n",
       "       'r/personalfinance', 'r/creepy', 'r/TwoXChromosomes',\n",
       "       'r/technology', 'r/Fitness', 'r/wholesomememes', 'r/politics',\n",
       "       'r/interestingasfuck', 'r/WTF', 'r/bestof', 'r/travel',\n",
       "       'r/oddlysatisfying', 'r/leagueoflegends', 'r/me_irl',\n",
       "       'r/lifehacks', 'r/NatureIsFuckingLit', 'r/pcmasterrace',\n",
       "       'r/dankmemes', 'r/Whatcouldgowrong', 'r/Tinder',\n",
       "       'r/relationship_advice', 'r/Minecraft', 'r/PS4', 'r/nba',\n",
       "       'r/woahdude', 'r/FoodPorn', 'r/photography', 'r/Overwatch',\n",
       "       'r/Unexpected', 'r/dadjokes', 'r/relationships', 'r/boardgames',\n",
       "       'r/instant_regret', 'r/programming', 'r/PublicFreakout',\n",
       "       'r/pokemon', 'r/pokemongo'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df['Subreddit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r/nosleep                998\n",
       "r/Jokes                  995\n",
       "r/IAmA                   994\n",
       "r/tifu                   989\n",
       "r/Fitness                989\n",
       "r/personalfinance        974\n",
       "r/dadjokes               906\n",
       "r/relationship_advice    869\n",
       "r/relationships          839\n",
       "r/LifeProTips            547\n",
       "r/history                543\n",
       "r/boardgames             536\n",
       "r/askscience             506\n",
       "r/TwoXChromosomes        505\n",
       "r/leagueoflegends        443\n",
       "r/books                  346\n",
       "r/explainlikeimfive      340\n",
       "r/photography            301\n",
       "r/nba                    258\n",
       "r/Music                  191\n",
       "r/pokemongo              127\n",
       "r/Showerthoughts         120\n",
       "r/WritingPrompts         118\n",
       "r/blog                    76\n",
       "r/pokemon                 75\n",
       "r/listentothis            67\n",
       "r/PS4                     66\n",
       "r/politics                64\n",
       "r/movies                  62\n",
       "r/television              60\n",
       "r/Overwatch               58\n",
       "r/philosophy              31\n",
       "r/technology              26\n",
       "r/lifehacks               20\n",
       "r/space                   19\n",
       "r/GetMotivated            16\n",
       "r/AskReddit               11\n",
       "r/gaming                  10\n",
       "r/Futurology               8\n",
       "r/interestingasfuck        6\n",
       "r/science                  5\n",
       "r/DIY                      5\n",
       "r/woahdude                 5\n",
       "r/pcmasterrace             5\n",
       "r/Tinder                   4\n",
       "r/InternetIsBeautiful      3\n",
       "r/Whatcouldgowrong         2\n",
       "r/oddlysatisfying          2\n",
       "r/me_irl                   2\n",
       "r/sports                   2\n",
       "r/photoshopbattles         2\n",
       "r/programming              2\n",
       "r/dankmemes                2\n",
       "r/travel                   2\n",
       "r/videos                   2\n",
       "r/Minecraft                2\n",
       "r/instant_regret           1\n",
       "r/NatureIsFuckingLit       1\n",
       "r/EarthPorn                1\n",
       "r/PublicFreakout           1\n",
       "r/WTF                      1\n",
       "r/aww                      1\n",
       "r/OldSchoolCool            1\n",
       "r/gadgets                  1\n",
       "r/Unexpected               1\n",
       "r/bestof                   1\n",
       "r/worldnews                1\n",
       "r/wholesomememes           1\n",
       "r/UpliftingNews            1\n",
       "r/creepy                   1\n",
       "r/nottheonion              1\n",
       "r/FoodPorn                 1\n",
       "Name: Subreddit, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 10000)\n",
    "\n",
    "# value counts of subreddits \n",
    "subreddit_df['Subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with subreddit dadjokes and jokes\n",
    "subreddit_df.drop(subreddit_df[(subreddit_df['Subreddit'] == 'r/dadjokes') | \n",
    "                               (subreddit_df['Subreddit'] == 'r/Jokes') | \n",
    "                               (subreddit_df['Subreddit'] == 'r/tifu') |\n",
    "                               (subreddit_df['Subreddit'] == 'r/IAmA') |\n",
    "                               (subreddit_df['Subreddit'] == 'r/Overwatch') | \n",
    "                               (subreddit_df['Subreddit'] == 'r/WTF') |\n",
    "                               (subreddit_df['Subreddit'] == 'r/DIY') |\n",
    "                               (subreddit_df['Subreddit'] == 'r/listentothis') |\n",
    "                               (subreddit_df['Subreddit'] == 'r/bestof') |\n",
    "                               (subreddit_df['Subreddit'] == 'r/me_irl') |\n",
    "                               (subreddit_df['Subreddit'] == 'r/woahdude') |\n",
    "                               (subreddit_df['Subreddit'] == 'r/Unexpected') |\n",
    "                               (subreddit_df['Subreddit'] == 'r/nba') |\n",
    "                               (subreddit_df['Subreddit'] == 'r/instant_regret')].index, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df[subreddit_df['Subreddit'] == 'r/dadjokes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Professor Stephen Hawking has passed away at t...</td>\n",
       "      <td>We have lost one of the greatest minds in hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Suicide Prevention Megathread</td>\n",
       "      <td>With the news today of the passing of the amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>I can’t breathe. Black lives matter.</td>\n",
       "      <td>As the gap of the political divide in our worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>[Breaking News] Orlando Nightclub mass-shooting.</td>\n",
       "      <td>**Update 3:19PM EST:** Updated links below\\n\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Subreddit                                              Title  \\\n",
       "3   r/AskReddit           Stan Lee has passed away at 95 years old   \n",
       "21  r/AskReddit  Professor Stephen Hawking has passed away at t...   \n",
       "34  r/AskReddit                      Suicide Prevention Megathread   \n",
       "48  r/AskReddit               I can’t breathe. Black lives matter.   \n",
       "55  r/AskReddit   [Breaking News] Orlando Nightclub mass-shooting.   \n",
       "\n",
       "                                                 Post  \n",
       "3   As many of you know today is day that many of ...  \n",
       "21  We have lost one of the greatest minds in hist...  \n",
       "34  With the news today of the passing of the amaz...  \n",
       "48  As the gap of the political divide in our worl...  \n",
       "55  **Update 3:19PM EST:** Updated links below\\n\\n...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.sub('[^a-zA-Z 0-9]', ' ', text)\n",
    "    tokens = tokens.lower().split()\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_df['Post_tokens'] = subreddit_df['Post'].apply(tokenize)\n",
    "subreddit_df['Title_tokens'] = subreddit_df['Title'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08472772,  0.58565724, -0.42876625, -0.415778  ,  2.2238202 ,\n",
       "       -0.00735564, -0.02597037, -0.47321063,  1.2979314 ,  0.698425  ,\n",
       "        0.17930374, -0.8026657 ,  0.21522038, -0.877949  , -0.92322516,\n",
       "       -0.39935544, -0.7269814 ,  0.78691673,  0.60622007, -0.10287637,\n",
       "        0.38252005, -0.49237317, -1.0594755 ,  0.24939926, -0.47489786,\n",
       "        0.42249155, -0.8828142 , -0.86617047,  0.86329645, -0.08447525,\n",
       "       -0.4069337 , -0.05806416,  0.640145  ,  0.455101  ,  0.38941973,\n",
       "        1.2069393 ,  0.49642405, -1.0259969 ,  1.2258627 , -0.18787678,\n",
       "        1.3801413 ,  0.7176436 , -0.31616357, -2.2108443 , -1.4399089 ,\n",
       "       -0.7518394 ,  1.0237472 ,  0.2505633 , -0.7356317 ,  0.67306155,\n",
       "       -0.08155   , -1.1917182 , -1.0981673 , -0.42740417, -1.3408034 ,\n",
       "        1.1213357 , -0.9313327 ,  0.42194656,  0.10266546, -0.38030586,\n",
       "       -0.2765135 ,  0.26392233,  0.8711452 ,  0.23050681, -0.11067268,\n",
       "        0.27325147,  0.6958853 , -0.9966496 , -0.14798068,  0.8054352 ,\n",
       "        1.696953  , -0.43569127,  0.39996144,  0.5505795 , -0.8240836 ,\n",
       "        0.35744452, -0.5779679 ,  1.1650243 , -0.60788846, -0.22375555,\n",
       "        0.26813418, -0.21171853,  1.1147381 , -0.63216335,  0.40878767,\n",
       "        0.67902076,  0.29976538,  0.1176309 , -0.18270223,  0.36829367,\n",
       "        0.01456616, -0.8050619 , -0.02746438,  0.09811432,  0.48134974,\n",
       "       -0.24564357], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_tokens = subreddit_df['Title_tokens'] + subreddit_df['Post_tokens']\n",
    "# feature = feature.apply(lambda x: ','.join(map(str, x)))\n",
    "doc = nlp(feature_tokens.to_string())\n",
    "nlp_vector = doc.vector\n",
    "nlp_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7911,) (1978,) (7911,) (1978,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Arrange data into X features matrix and y target vector \n",
    "\n",
    "features = subreddit_df['Title'] + subreddit_df['Post']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    subreddit_df['Subreddit'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(document):\n",
    "    doc = nlp(document)\n",
    "    return [token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1 = get_word_vectors(X_train)\n",
    "len(X_train1) == len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1 = get_word_vectors(X_test)\n",
    "len(X_test1) == len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from random import randint\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khisl\\anaconda3\\envs\\post-here\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "clf = RandomizedSearchCV(rfc, param_dist, n_iter=10, cv=3, random_state=1)\n",
    "\n",
    "clf = clf.fit(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 6,\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 5,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# print winning set of hyperparameters\n",
    "pprint(clf.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43427704752275026"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Evaluate on test data\n",
    "y_pred = clf.predict(X_test1)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4262419416003034"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "          r/AskReddit       0.00      0.00      0.00         3\n",
      "            r/Fitness       0.37      0.62      0.46       199\n",
      "         r/Futurology       0.00      0.00      0.00         1\n",
      "       r/GetMotivated       0.00      0.00      0.00         2\n",
      "        r/LifeProTips       0.38      0.44      0.41       106\n",
      "              r/Music       0.00      0.00      0.00        37\n",
      "      r/OldSchoolCool       0.00      0.00      0.00         1\n",
      "                r/PS4       0.00      0.00      0.00        13\n",
      "     r/Showerthoughts       0.00      0.00      0.00        29\n",
      "             r/Tinder       0.00      0.00      0.00         1\n",
      "    r/TwoXChromosomes       0.26      0.06      0.10       100\n",
      "     r/WritingPrompts       0.00      0.00      0.00        26\n",
      "         r/askscience       0.28      0.37      0.32       105\n",
      "               r/blog       1.00      0.29      0.45        17\n",
      "         r/boardgames       0.29      0.21      0.24        87\n",
      "              r/books       0.55      0.08      0.14        74\n",
      "  r/explainlikeimfive       0.35      0.10      0.16        67\n",
      "             r/gaming       0.00      0.00      0.00         5\n",
      "            r/history       0.37      0.69      0.49        85\n",
      "  r/interestingasfuck       0.00      0.00      0.00         1\n",
      "    r/leagueoflegends       0.31      0.17      0.22        90\n",
      "          r/lifehacks       0.00      0.00      0.00         7\n",
      "             r/movies       0.00      0.00      0.00        11\n",
      "            r/nosleep       0.72      0.90      0.80       209\n",
      "        r/nottheonion       0.00      0.00      0.00         1\n",
      "    r/oddlysatisfying       0.00      0.00      0.00         1\n",
      "       r/pcmasterrace       0.00      0.00      0.00         1\n",
      "    r/personalfinance       0.40      0.69      0.50       207\n",
      "         r/philosophy       0.00      0.00      0.00        11\n",
      "        r/photography       0.00      0.00      0.00        64\n",
      "   r/photoshopbattles       0.00      0.00      0.00         1\n",
      "            r/pokemon       0.00      0.00      0.00        15\n",
      "          r/pokemongo       0.00      0.00      0.00        28\n",
      "           r/politics       0.67      0.89      0.76         9\n",
      "        r/programming       0.00      0.00      0.00         1\n",
      "r/relationship_advice       0.43      0.59      0.50       175\n",
      "      r/relationships       0.50      0.55      0.53       165\n",
      "            r/science       0.00      0.00      0.00         1\n",
      "              r/space       0.00      0.00      0.00         6\n",
      "         r/technology       0.00      0.00      0.00         7\n",
      "         r/television       0.00      0.00      0.00         9\n",
      "\n",
      "             accuracy                           0.43      1978\n",
      "            macro avg       0.17      0.16      0.15      1978\n",
      "         weighted avg       0.37      0.43      0.38      1978\n",
      "\n",
      "[[  0   1   0 ...   0   0   0]\n",
      " [  0 124   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   1   0 ...   0   0   0]\n",
      " [  0   3   0 ...   0   0   0]\n",
      " [  0   1   0 ...   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khisl\\anaconda3\\envs\\post-here\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "reddit_post =[ \"\"\"Hi, I lost my dog about 3 months ago and straight away started doing research \n",
    "            on rabbits to distract myself. I started asking my parents to get me a rabbit and \n",
    "            my mum found a rabbit and we went to pick him up. I still miss my dog so much and \n",
    "            I’m crying almost every night. I started looking into rehoming him but I don’t want \n",
    "            to get rid of him because I know I’ll regret it. He is so much work and even though \n",
    "            I knew how much work they were I still wanted one. \"\"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/relationship_advice'], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test predictions\n",
    "test1 = get_word_vectors(reddit_post)\n",
    "clf.predict(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "post2 = [\"\"\"The plan to turn half the world into a reserve for nature. \n",
    "        Scientists and conservationists are proposing that up to half of \n",
    "        Earth’s land and oceans be protected for nature.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/askscience'], dtype=object)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test predictions\n",
    "test2 = get_word_vectors(post2)\n",
    "clf.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "post3 = [\"\"\"Pets get flooded constantly and need help.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/askscience'], dtype=object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test predictions\n",
    "test3 = get_word_vectors(post3)\n",
    "clf.predict(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]\n",
    "\n",
    "def subreddit_prediction(title, text, num_pred):\n",
    "    title = pd.Series(title)\n",
    "    text = pd.Series(text)\n",
    "    df = pd.concat([title, text], axis=1)\n",
    "    str_input = [f'{df}']\n",
    "    vect = get_word_vectors(str_input)\n",
    "    proba = clf.predict_proba(vect)[0]\n",
    "    proba = pd.Series(proba)\n",
    "    proba = clf.classes_\n",
    "    prediction = pd.Series(proba).sort_values(ascending=False)\n",
    "    prediction = prediction.reset_index(drop=True)\n",
    "    \n",
    "    if num_pred > 1:\n",
    "        return prediction[:num_pred] \n",
    "    else:\n",
    "        return prediction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    r/worldnews\n",
       "dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function with one prediction \n",
    "subreddit_prediction(['Any remote employees working US hours?'], [\"\"\"I see a lot of posts of \n",
    "                   people with remote US based jobs moving to Korea because they can work \n",
    "                   wherever they want regardless of time zone.\"\"\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         r/worldnews\n",
       "1    r/wholesomememes\n",
       "2            r/videos\n",
       "3            r/travel\n",
       "dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function with n predictions \n",
    "subreddit_prediction([\"\"\"Advice needed. My hair has become so much more oily within the past year. \n",
    "                   Can’t figure out why and it’s driving me crazy!\"\"\"], [\"\"\"I have always had somewhat oily hair.\n",
    "                   My second day hair had a little bit of oil to it, but nothing too drastic.\n",
    "                   I got highlights (my first experience with hair color) approximately a year ago. \n",
    "                   Since then, my hair has become grossly oily. It even feels oily when I blow dry \n",
    "                   it after a shower, when it should be completely clean.\"\"\"], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pickle import dump\n",
    "filename = 'post_here_model.pkl'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "\n",
    "# to load model\n",
    "load_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "\n",
    "def compressed_pickle(title, data):\n",
    "    with bz2.BZ2File(title + '.pbz2', 'w') as f: \n",
    "        cPickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_pickle('post_here_model_new', clf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load any compressed pickle file\n",
    "def decompress_pickle(file):\n",
    "    data = bz2.BZ2File(file, 'rb')\n",
    "    data = cPickle.load(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42),\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [3, None],\n",
       "                                        'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002ABBC5D35C0>,\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002ABBC601C50>},\n",
       "                   random_state=1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model = decompress_pickle('post_here_model.pbz2') \n",
    "clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# import spacy.cli\n",
    "# spacy.cli.download(\"en_core_web_sm\")\n",
    "# import en_core_web_sm\n",
    "\n",
    "# # Load any compressed pickle file\n",
    "# def decompress_pickle(file):\n",
    "#     data = bz2.BZ2File(file, 'rb')\n",
    "#     data = cPickle.load(data)\n",
    "#     return data\n",
    "\n",
    "# clf_model = decompress_pickle('post_here_model.pbz2') \n",
    "# clf_model\n",
    "\n",
    "# nlp = en_core_web_sm.load()\n",
    "\n",
    "# def get_word_vectors(docs):\n",
    "#     return [nlp(doc).vector for doc in docs]\n",
    "\n",
    "# def subreddit_prediction(title, text, num_pred):\n",
    "#     title = pd.Series(title)\n",
    "#     text = pd.Series(text)\n",
    "#     df = pd.concat([title, text], axis=1)\n",
    "#     str_input = [f'{df}']\n",
    "#     vect = get_word_vectors(str_input)\n",
    "#     proba = clf_model.predict_proba(vect)[0]\n",
    "#     proba = pd.Series(proba)\n",
    "#     proba = clf_model.classes_\n",
    "#     prediction = pd.Series(proba).sort_values(ascending=False)\n",
    "#     if num_pred > 1:\n",
    "#         return prediction[:num_pred] \n",
    "#     else:\n",
    "#         return prediction[:1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
