{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People who haven't pooped in 2019 yet, why are...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221854</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Would you watch a show where a billionaire CEO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197524</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How would you feel about a feature where if so...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186368</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "      <td>175339</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reddit, how would you feel about a law that ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160311</td>\n",
       "      <td>r/AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>Pokemon Go Update [2016-08-08]</td>\n",
       "      <td># [A Note From The Developers](http://pokemong...</td>\n",
       "      <td>7189</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18573</th>\n",
       "      <td>It boggles my mind that there is no way to sig...</td>\n",
       "      <td>It seems to me like a really obvious and easy ...</td>\n",
       "      <td>7168</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18574</th>\n",
       "      <td>Is it really a coincidence that both Niantic a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7117</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18575</th>\n",
       "      <td>The three footstep glitch has turned the game ...</td>\n",
       "      <td>The servers are slowly getting better. Hopeful...</td>\n",
       "      <td>7108</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18576</th>\n",
       "      <td>I feel like transfering second and third stage...</td>\n",
       "      <td>Not anything outrageous. Say a basic pokemon g...</td>\n",
       "      <td>7097</td>\n",
       "      <td>r/pokemongo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18577 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      People who haven't pooped in 2019 yet, why are...   \n",
       "1      Would you watch a show where a billionaire CEO...   \n",
       "2      How would you feel about a feature where if so...   \n",
       "3               Stan Lee has passed away at 95 years old   \n",
       "4      Reddit, how would you feel about a law that ba...   \n",
       "...                                                  ...   \n",
       "18572                     Pokemon Go Update [2016-08-08]   \n",
       "18573  It boggles my mind that there is no way to sig...   \n",
       "18574  Is it really a coincidence that both Niantic a...   \n",
       "18575  The three footstep glitch has turned the game ...   \n",
       "18576  I feel like transfering second and third stage...   \n",
       "\n",
       "                                                    text  up_votes  \\\n",
       "0                                                    NaN    221854   \n",
       "1                                                    NaN    197524   \n",
       "2                                                    NaN    186368   \n",
       "3      As many of you know today is day that many of ...    175339   \n",
       "4                                                    NaN    160311   \n",
       "...                                                  ...       ...   \n",
       "18572  # [A Note From The Developers](http://pokemong...      7189   \n",
       "18573  It seems to me like a really obvious and easy ...      7168   \n",
       "18574                                                NaN      7117   \n",
       "18575  The servers are slowly getting better. Hopeful...      7108   \n",
       "18576  Not anything outrageous. Say a basic pokemon g...      7097   \n",
       "\n",
       "         subreddit  \n",
       "0      r/AskReddit  \n",
       "1      r/AskReddit  \n",
       "2      r/AskReddit  \n",
       "3      r/AskReddit  \n",
       "4      r/AskReddit  \n",
       "...            ...  \n",
       "18572  r/pokemongo  \n",
       "18573  r/pokemongo  \n",
       "18574  r/pokemongo  \n",
       "18575  r/pokemongo  \n",
       "18576  r/pokemongo  \n",
       "\n",
       "[18577 rows x 4 columns]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "filepath = 'reddit_posts.xlsx'\n",
    "subreddit_df = pd.read_excel(filepath)\n",
    "subreddit_df = subreddit_df.drop(['Unnamed: 0'], axis=1)\n",
    "subreddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18577, 4)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_df = subreddit_df[['subreddit', 'title', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>People who haven't pooped in 2019 yet, why are...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Would you watch a show where a billionaire CEO...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>How would you feel about a feature where if so...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Reddit, how would you feel about a law that ba...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>Pokemon Go Update [2016-08-08]</td>\n",
       "      <td># [A Note From The Developers](http://pokemong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18573</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>It boggles my mind that there is no way to sig...</td>\n",
       "      <td>It seems to me like a really obvious and easy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18574</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>Is it really a coincidence that both Niantic a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18575</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>The three footstep glitch has turned the game ...</td>\n",
       "      <td>The servers are slowly getting better. Hopeful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18576</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>I feel like transfering second and third stage...</td>\n",
       "      <td>Not anything outrageous. Say a basic pokemon g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18577 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subreddit                                              Title  \\\n",
       "0      r/AskReddit  People who haven't pooped in 2019 yet, why are...   \n",
       "1      r/AskReddit  Would you watch a show where a billionaire CEO...   \n",
       "2      r/AskReddit  How would you feel about a feature where if so...   \n",
       "3      r/AskReddit           Stan Lee has passed away at 95 years old   \n",
       "4      r/AskReddit  Reddit, how would you feel about a law that ba...   \n",
       "...            ...                                                ...   \n",
       "18572  r/pokemongo                     Pokemon Go Update [2016-08-08]   \n",
       "18573  r/pokemongo  It boggles my mind that there is no way to sig...   \n",
       "18574  r/pokemongo  Is it really a coincidence that both Niantic a...   \n",
       "18575  r/pokemongo  The three footstep glitch has turned the game ...   \n",
       "18576  r/pokemongo  I feel like transfering second and third stage...   \n",
       "\n",
       "                                                    Post  \n",
       "0                                                    NaN  \n",
       "1                                                    NaN  \n",
       "2                                                    NaN  \n",
       "3      As many of you know today is day that many of ...  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "18572  # [A Note From The Developers](http://pokemong...  \n",
       "18573  It seems to me like a really obvious and easy ...  \n",
       "18574                                                NaN  \n",
       "18575  The servers are slowly getting better. Hopeful...  \n",
       "18576  Not anything outrageous. Say a basic pokemon g...  \n",
       "\n",
       "[18577 rows x 3 columns]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df = subreddit_df.rename(columns={\"subreddit\": \"Subreddit\",\"title\": \"Title\", \"text\": \"Post\"})\n",
    "nan_value = float(\"NaN\")\n",
    "subreddit_df.replace(\" \", nan_value, inplace=True)\n",
    "subreddit_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18577, 3)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subreddit       0\n",
       "Title           0\n",
       "Post         4405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14172, 3)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Professor Stephen Hawking has passed away at t...</td>\n",
       "      <td>We have lost one of the greatest minds in hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Suicide Prevention Megathread</td>\n",
       "      <td>With the news today of the passing of the amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>I can t breathe  Black lives matter</td>\n",
       "      <td>As the gap of the political divide in our worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Breaking News  Orlando Nightclub mass shooting</td>\n",
       "      <td>Update 3 19PM EST    Updated links below    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Subreddit                                              Title  \\\n",
       "3   r/AskReddit           Stan Lee has passed away at 95 years old   \n",
       "21  r/AskReddit  Professor Stephen Hawking has passed away at t...   \n",
       "34  r/AskReddit                      Suicide Prevention Megathread   \n",
       "48  r/AskReddit               I can t breathe  Black lives matter    \n",
       "55  r/AskReddit    Breaking News  Orlando Nightclub mass shooting    \n",
       "\n",
       "                                                 Post  \n",
       "3   As many of you know today is day that many of ...  \n",
       "21  We have lost one of the greatest minds in hist...  \n",
       "34  With the news today of the passing of the amaz...  \n",
       "48  As the gap of the political divide in our worl...  \n",
       "55    Update 3 19PM EST    Updated links below    ...  "
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df['Post'] = subreddit_df['Post'].apply(lambda x: re.sub('[^a-z A-Z 0-9]',' ', x))\n",
    "subreddit_df['Title'] = subreddit_df['Title'].apply(lambda x: re.sub('[^a-zA-Z0-9]',' ', x))\n",
    "subreddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Stan Lee has passed away at 95 years old</td>\n",
       "      <td>As many of you know today is day that many of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Professor Stephen Hawking has passed away at t...</td>\n",
       "      <td>We have lost one of the greatest minds in hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Suicide Prevention Megathread</td>\n",
       "      <td>With the news today of the passing of the amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>I can t breathe  Black lives matter</td>\n",
       "      <td>As the gap of the political divide in our worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r/AskReddit</td>\n",
       "      <td>Breaking News  Orlando Nightclub mass shooting</td>\n",
       "      <td>Update 3 19PM EST    Updated links below    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14167</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>3 Months After His Death  the Gym in our Town ...</td>\n",
       "      <td>UPDATE 2  The name of the Gym has been change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14168</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>Pokemon Go Update  2016 08 08</td>\n",
       "      <td>A Note From The Developers  http   pokemong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14169</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>It boggles my mind that there is no way to sig...</td>\n",
       "      <td>It seems to me like a really obvious and easy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14170</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>The three footstep glitch has turned the game ...</td>\n",
       "      <td>The servers are slowly getting better  Hopeful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14171</th>\n",
       "      <td>r/pokemongo</td>\n",
       "      <td>I feel like transfering second and third stage...</td>\n",
       "      <td>Not anything outrageous  Say a basic pokemon g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14172 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subreddit                                              Title  \\\n",
       "0      r/AskReddit           Stan Lee has passed away at 95 years old   \n",
       "1      r/AskReddit  Professor Stephen Hawking has passed away at t...   \n",
       "2      r/AskReddit                      Suicide Prevention Megathread   \n",
       "3      r/AskReddit               I can t breathe  Black lives matter    \n",
       "4      r/AskReddit    Breaking News  Orlando Nightclub mass shooting    \n",
       "...            ...                                                ...   \n",
       "14167  r/pokemongo  3 Months After His Death  the Gym in our Town ...   \n",
       "14168  r/pokemongo                     Pokemon Go Update  2016 08 08    \n",
       "14169  r/pokemongo  It boggles my mind that there is no way to sig...   \n",
       "14170  r/pokemongo  The three footstep glitch has turned the game ...   \n",
       "14171  r/pokemongo  I feel like transfering second and third stage...   \n",
       "\n",
       "                                                    Post  \n",
       "0      As many of you know today is day that many of ...  \n",
       "1      We have lost one of the greatest minds in hist...  \n",
       "2      With the news today of the passing of the amaz...  \n",
       "3      As the gap of the political divide in our worl...  \n",
       "4        Update 3 19PM EST    Updated links below    ...  \n",
       "...                                                  ...  \n",
       "14167   UPDATE 2  The name of the Gym has been change...  \n",
       "14168     A Note From The Developers  http   pokemong...  \n",
       "14169  It seems to me like a really obvious and easy ...  \n",
       "14170  The servers are slowly getting better  Hopeful...  \n",
       "14171  Not anything outrageous  Say a basic pokemon g...  \n",
       "\n",
       "[14172 rows x 3 columns]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/AskReddit', 'r/gaming', 'r/aww', 'r/Music', 'r/science',\n",
       "       'r/worldnews', 'r/videos', 'r/movies', 'r/Showerthoughts',\n",
       "       'r/IAmA', 'r/EarthPorn', 'r/askscience', 'r/Jokes',\n",
       "       'r/explainlikeimfive', 'r/books', 'r/LifeProTips', 'r/blog',\n",
       "       'r/DIY', 'r/sports', 'r/nottheonion', 'r/space', 'r/gadgets',\n",
       "       'r/television', 'r/GetMotivated', 'r/photoshopbattles',\n",
       "       'r/listentothis', 'r/UpliftingNews', 'r/tifu',\n",
       "       'r/InternetIsBeautiful', 'r/history', 'r/philosophy',\n",
       "       'r/Futurology', 'r/OldSchoolCool', 'r/WritingPrompts', 'r/nosleep',\n",
       "       'r/personalfinance', 'r/creepy', 'r/TwoXChromosomes',\n",
       "       'r/technology', 'r/Fitness', 'r/wholesomememes', 'r/politics',\n",
       "       'r/interestingasfuck', 'r/WTF', 'r/bestof', 'r/travel',\n",
       "       'r/oddlysatisfying', 'r/leagueoflegends', 'r/me_irl',\n",
       "       'r/lifehacks', 'r/NatureIsFuckingLit', 'r/pcmasterrace',\n",
       "       'r/dankmemes', 'r/Whatcouldgowrong', 'r/Tinder',\n",
       "       'r/relationship_advice', 'r/Minecraft', 'r/PS4', 'r/nba',\n",
       "       'r/woahdude', 'r/FoodPorn', 'r/photography', 'r/Overwatch',\n",
       "       'r/Unexpected', 'r/dadjokes', 'r/relationships', 'r/boardgames',\n",
       "       'r/instant_regret', 'r/programming', 'r/PublicFreakout',\n",
       "       'r/pokemon', 'r/pokemongo'], dtype=object)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df['Subreddit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_df.drop(subreddit_df[(subreddit_df['Subreddit'] == 'r/dadjokes') | \n",
    "                               (subreddit_df['Subreddit'] == 'r/Jokes')].index, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_df[subreddit_df['Subreddit'] == 'r/dadjokes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9816, 3), (2455, 3))"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(subreddit_df, test_size=0.20, random_state=42)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9816,), (9816,), (2455,), (2455,))"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arrange data into X features matrix and y target vector \n",
    "\n",
    "target = 'Subreddit'\n",
    "feature = 'Title'\n",
    "feature1 = 'Post'\n",
    "X_train = train[feature] + train[feature1] \n",
    "y_train = train[target]\n",
    "X_test = test[feature] + test[feature1] \n",
    "y_test = test[target]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10322    She Sold Happiness in Glass JarsThe poster rea...\n",
       "6295     My favorite quote about books from Ursula Le G...\n",
       "8569     TIFU by eating the green pasteThis happened ye...\n",
       "18304    The best thing about Hero Quest is    I don t ...\n",
       "7704      Discussion  What s your audible anti depressa...\n",
       "                               ...                        \n",
       "18258    List of recommended official authorized Tablet...\n",
       "10431    The Worst Wedding I ve Ever PhotographedI ve b...\n",
       "10630    KrampusEach year on December 5th  a person in ...\n",
       "2678     I am a pest controller specializing in BED BUG...\n",
       "12528    I ve gained a lot of weight and my husband fin...\n",
       "Length: 9816, dtype: object"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('lsi',\n",
      "                 Pipeline(memory=None,\n",
      "                          steps=[('vect',\n",
      "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                                  decode_error='strict',\n",
      "                                                  dtype=<class 'numpy.float64'>,\n",
      "                                                  encoding='utf-8',\n",
      "                                                  input='content',\n",
      "                                                  lowercase=True, max_df=1.0,\n",
      "                                                  max_features=None, min_df=1,\n",
      "                                                  ngram_range=(1, 2), norm='l2',\n",
      "                                                  preprocessor=None,\n",
      "                                                  smooth_idf=True,\n",
      "                                                  stop_words='english',\n",
      "                                                  strip_accents=...\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=None, max_features='auto',\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=-1,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from random import randint\n",
    "from scipy.stats import randint\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "svd = TruncatedSVD(n_components=100, # svd = singular value decomposition \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators =100, n_jobs=-1, random_state=42)\n",
    "\n",
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "# Pipe\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])\n",
    "print(pipe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "\n",
    "parameters = {\n",
    "    'lsi__svd__n_components': scipy.stats.randint(5, 100),\n",
    "    'lsi__vect__max_features': scipy.stats.randint(100, 1000), # has to be an integer\n",
    "    'clf__n_estimators': scipy.stats.randint(10, 100),\n",
    "    'clf__max_depth': scipy.stats.randint(10, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khisl\\anaconda3\\envs\\post-here\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('lsi',\n",
       "                                              Pipeline(memory=None,\n",
       "                                                       steps=[('vect',\n",
       "                                                               TfidfVectorizer(analyzer='word',\n",
       "                                                                               binary=False,\n",
       "                                                                               decode_error='strict',\n",
       "                                                                               dtype=<class 'numpy.float64'>,\n",
       "                                                                               encoding='utf-8',\n",
       "                                                                               input='content',\n",
       "                                                                               lowercase=True,\n",
       "                                                                               max_df=1.0,\n",
       "                                                                               max_features=None,\n",
       "                                                                               min_df=1,\n",
       "                                                                               ngram_range=(1,\n",
       "                                                                                            2),\n",
       "                                                                               norm='l2',\n",
       "                                                                               preprocessor=None,\n",
       "                                                                               s...\n",
       "                                        'clf__n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B56BB31E10>,\n",
       "                                        'lsi__svd__n_components': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B56BB311D0>,\n",
       "                                        'lsi__vect__max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B56BB31320>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search = RandomizedSearchCV(pipe, parameters, n_iter=10, cv=5, n_jobs=-1, verbose=1)\n",
    "rand_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6113502027840922"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/AskReddit', 'r/DIY', 'r/EarthPorn', 'r/Fitness', 'r/FoodPorn',\n",
       "       'r/Futurology', 'r/GetMotivated', 'r/IAmA',\n",
       "       'r/InternetIsBeautiful', 'r/LifeProTips', 'r/Minecraft', 'r/Music',\n",
       "       'r/NatureIsFuckingLit', 'r/OldSchoolCool', 'r/Overwatch', 'r/PS4',\n",
       "       'r/PublicFreakout', 'r/Showerthoughts', 'r/Tinder',\n",
       "       'r/TwoXChromosomes', 'r/Unexpected', 'r/UpliftingNews', 'r/WTF',\n",
       "       'r/Whatcouldgowrong', 'r/WritingPrompts', 'r/askscience', 'r/aww',\n",
       "       'r/bestof', 'r/blog', 'r/boardgames', 'r/books', 'r/creepy',\n",
       "       'r/dankmemes', 'r/explainlikeimfive', 'r/gadgets', 'r/gaming',\n",
       "       'r/history', 'r/instant_regret', 'r/interestingasfuck',\n",
       "       'r/leagueoflegends', 'r/lifehacks', 'r/listentothis', 'r/me_irl',\n",
       "       'r/movies', 'r/nba', 'r/nosleep', 'r/nottheonion',\n",
       "       'r/oddlysatisfying', 'r/pcmasterrace', 'r/personalfinance',\n",
       "       'r/philosophy', 'r/photography', 'r/photoshopbattles', 'r/pokemon',\n",
       "       'r/pokemongo', 'r/politics', 'r/programming',\n",
       "       'r/relationship_advice', 'r/relationships', 'r/science', 'r/space',\n",
       "       'r/sports', 'r/technology', 'r/television', 'r/tifu', 'r/travel',\n",
       "       'r/videos', 'r/woahdude'], dtype=object)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rand_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "          r/AskReddit       0.00      0.00      0.00         3\n",
      "            r/Fitness       0.76      0.91      0.82       215\n",
      "         r/Futurology       0.00      0.00      0.00         1\n",
      "       r/GetMotivated       0.00      0.00      0.00         5\n",
      "               r/IAmA       0.66      0.94      0.78       199\n",
      "        r/LifeProTips       0.36      0.42      0.39       119\n",
      "              r/Music       0.56      0.44      0.49        41\n",
      "          r/Overwatch       0.00      0.00      0.00        16\n",
      "                r/PS4       0.00      0.00      0.00         9\n",
      "     r/Showerthoughts       0.12      0.04      0.06        25\n",
      "             r/Tinder       0.00      0.00      0.00         1\n",
      "    r/TwoXChromosomes       0.53      0.37      0.44        99\n",
      "   r/Whatcouldgowrong       0.00      0.00      0.00         1\n",
      "     r/WritingPrompts       0.22      0.10      0.13        21\n",
      "         r/askscience       0.41      0.53      0.46       105\n",
      "               r/blog       0.53      0.67      0.59        12\n",
      "         r/boardgames       0.51      0.88      0.64        88\n",
      "              r/books       0.82      0.82      0.82        77\n",
      "          r/dankmemes       0.00      0.00      0.00         1\n",
      "  r/explainlikeimfive       0.24      0.16      0.19        70\n",
      "             r/gaming       0.00      0.00      0.00         3\n",
      "            r/history       0.69      0.62      0.66       109\n",
      "  r/interestingasfuck       0.50      1.00      0.67         1\n",
      "    r/leagueoflegends       0.63      0.39      0.48       101\n",
      "          r/lifehacks       0.00      0.00      0.00         4\n",
      "       r/listentothis       0.00      0.00      0.00        12\n",
      "             r/movies       0.00      0.00      0.00         9\n",
      "                r/nba       0.50      0.14      0.22        57\n",
      "            r/nosleep       0.90      0.95      0.92       204\n",
      "    r/personalfinance       0.71      0.80      0.75       184\n",
      "         r/philosophy       1.00      0.20      0.33         5\n",
      "        r/photography       0.77      0.43      0.55        54\n",
      "   r/photoshopbattles       0.00      0.00      0.00         0\n",
      "            r/pokemon       0.50      0.21      0.30        14\n",
      "          r/pokemongo       1.00      0.33      0.50        30\n",
      "           r/politics       1.00      1.00      1.00        13\n",
      "        r/programming       0.00      0.00      0.00         1\n",
      "r/relationship_advice       0.48      0.59      0.53       165\n",
      "      r/relationships       0.62      0.59      0.61       159\n",
      "            r/science       0.00      0.00      0.00         3\n",
      "              r/space       0.00      0.00      0.00         3\n",
      "             r/sports       0.00      0.00      0.00         1\n",
      "         r/technology       0.00      0.00      0.00         5\n",
      "         r/television       0.50      0.08      0.13        13\n",
      "               r/tifu       0.72      0.79      0.75       193\n",
      "     r/wholesomememes       0.00      0.00      0.00         1\n",
      "           r/woahdude       0.00      0.00      0.00         2\n",
      "          r/worldnews       0.00      0.00      0.00         1\n",
      "\n",
      "             accuracy                           0.63      2455\n",
      "            macro avg       0.34      0.30      0.30      2455\n",
      "         weighted avg       0.61      0.63      0.61      2455\n",
      "\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0 195   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khisl\\anaconda3\\envs\\post-here\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\khisl\\anaconda3\\envs\\post-here\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.classification_report(y_test, pred))\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "reddit_post =[ \"\"\"Hi, I lost my dog about 3 months ago and straight away started doing research \n",
    "            on rabbits to distract myself. I started asking my parents to get me a rabbit and \n",
    "            my mum found a rabbit and we went to pick him up. I still miss my dog so much and \n",
    "            I’m crying almost every night. I started looking into rehoming him but I don’t want \n",
    "            to get rid of him because I know I’ll regret it. He is so much work and even though \n",
    "            I knew how much work they were I still wanted one. \"\"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/relationship_advice'], dtype=object)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rand_search.predict(reddit_post)\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "post2 = [\"\"\"The plan to turn half the world into a reserve for nature. \n",
    "        Scientists and conservationists are proposing that up to half of \n",
    "        Earth’s land and oceans be protected for nature.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/askscience'], dtype=object)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rand_search.predict(post2)\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "post3 = [\"\"\"Pets get flooded constantly and need help.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r/LifeProTips'], dtype=object)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rand_search.predict(post3)\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_subreddit(text, num_pred):\n",
    "    proba = pd.Series(rand_search.predict_proba(text)[0])\n",
    "    proba = subreddit_df['Subreddit'].unique()\n",
    "    prediction = (pd.Series(proba).sort_values(ascending=False)).reset_index(drop=True)\n",
    "    if num_pred > 1:\n",
    "        return prediction[:num_pred]\n",
    "    else:\n",
    "        return prediction[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    r/worldnews\n",
       "dtype: object"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_subreddit(post3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    r/worldnews\n",
       "dtype: object"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_subreddit(['Hi'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         r/worldnews\n",
       "1          r/woahdude\n",
       "2    r/wholesomememes\n",
       "3            r/videos\n",
       "dtype: object"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_subreddit(post3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pickle import dump\n",
    "filename = 'post_here_model.pkl'\n",
    "pickle.dump(rand_search, open(filename, 'wb'))\n",
    "\n",
    "# to load model\n",
    "load_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "\n",
    "def compressed_pickle(title, data):\n",
    "    with bz2.BZ2File(title + '.pbz2', 'w') as f: \n",
    "        cPickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_pickle('post_here_model', rand_search) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load any compressed pickle file\n",
    "def decompress_pickle(file):\n",
    " data = bz2.BZ2File(file, ‘rb’)\n",
    " data = cPickle.load(data)\n",
    " return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = decompress_pickle('post_here_model.pbz2') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
